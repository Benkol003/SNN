{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import spikegen\n",
    "import snntorch.spikeplot as splt\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional\n",
    "\n",
    "import tonic\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "downsample_size = (128,128) #i think that downsampling removes too much information \n",
    "slice_meta_path = \"./tmp/DVS_sliced/\"\n",
    "\n",
    "dtype=torch.float\n",
    "torch.manual_seed(734)\n",
    "print(\"Convolutional SNN Trained on DVS Gesture\")\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Training Parameters\n",
    "batch_size=32 #you wanna set this so that the gpu uses all its dedicated memory but not any shared i.e. not swapping to main ram\n",
    "data_path='./tmp/data/DVS/'\n",
    "num_classes = 11  # DVS has 10 output classes, one for out of class\n",
    "\n",
    "frame_time = 10\n",
    "\n",
    "num_steps = 60  # assuming 16 steps as we use 16ms filter window, chip runs at 1ms; can also get decent accuracy using 16 timesteps on spiking MNIST\n",
    "# 60 frames 1ms or 5ms apart\n",
    "\n",
    "transform1 = tonic.transforms.Compose([tonic.transforms.ToFrame(sensor_size=(128,128,2),n_time_bins=num_steps), lambda x: x.astype(np.float32)]) #for some reason using time_window results in sometimes getting 95 frames\n",
    "\n",
    "#downsample to stay consistent with paper + helps save memory\n",
    "\n",
    "train_dvs = tonic.datasets.DVSGesture(data_path,train=True)\n",
    "test_dvs = tonic.datasets.DVSGesture(data_path,train=False)\n",
    "#TODO consider using  DiskCachedDataset for performance\n",
    "slicer = tonic.slicers.SliceByTime(60*frame_time*1000,59*frame_time*1000,False) #for some reason, it gives me one less frame than i need, hence 97=>96+1 (000)\n",
    "#allow an overlap such that we start a new slice at every 16ms - each frame in a 16ms window will be presented to feature i during training, but only once. if you want multiple exposure just use multiple epochs\n",
    " \n",
    "#TODO careful , you will need to regenerate after changing parameters, however without it takes about 30 seconds to generate the slices\n",
    "#slice our dataset - we do not need the entire dataset at once\n",
    "train_sliced_dvs = tonic.SlicedDataset(train_dvs,slicer=slicer,transform=transform1,metadata_path=slice_meta_path+\"train/\")\n",
    "test_sliced_dvs = tonic.SlicedDataset(test_dvs,slicer=slicer,transform=transform1,metadata_path=slice_meta_path+\"test/\")\n",
    "\n",
    "train_loader = DataLoader(train_sliced_dvs, batch_size=batch_size, shuffle=True,drop_last=False)\n",
    "test_loader = DataLoader(test_sliced_dvs, batch_size=batch_size, shuffle=True,drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training samples: \",len(train_sliced_dvs))\n",
    "print(\"testing samples: \",len(test_sliced_dvs))\n",
    "#if you want to create more samples you can change the overlap (but you might cause overfitting)\n",
    "\n",
    "a = next(iter(test_loader))\n",
    "print(test_dvs.classes[a[1][0]])\n",
    "print(a[0].shape)\n",
    "animation = tonic.utils.plot_animation(frames=a[0][0])\n",
    "display(HTML(animation.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "################ DVS Gesture Model #############################\n",
    "\n",
    "# (without temporal layer - this is up for interpretation)\n",
    "\n",
    "# layer parameters\n",
    "\n",
    "beta = 0.95\n",
    "lr=1e-4\n",
    "#weight_decay=1e-6\n",
    "\n",
    "spike_grad1 = surrogate.atan()\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loss = functional.ce_count_loss()\n",
    "        self.accuracy_metric = functional.accuracy_rate\n",
    "\n",
    "        #initialise neuron connections\n",
    "        #from table 1 in DVS paper\n",
    "        #TODO im multiplying features by two as paper states 6 input features, but we have seperate channels for increase/decrease events\n",
    "        self.layers = nn.ModuleList([\n",
    "            #64x64\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(2,64,3),\n",
    "            nn.Conv2d(64,128,3),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Conv2d(128,128,3),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Linear(4608,256),\n",
    "            nn.Linear(256,11)\n",
    "        ])\n",
    "\n",
    "        # initialize neurons\n",
    "        self.neurons = nn.ModuleList(\n",
    "            [snn.Leaky(beta=beta,spike_grad=spike_grad1)] * 8\n",
    "        )\n",
    "\n",
    "        self.to(device) #yes, this is needed twice\n",
    "        \n",
    "        #pytorch creates the tensors to represent the network layout and weights for each layer; snntorch provides the model that operates on the entire tensor (at each layer).\n",
    "\n",
    "  \n",
    "    def forward(self,x): #x is input data\n",
    "        #events should be treated as spikes i.e. already encoded\n",
    "\n",
    "        # Initialize hidden states\n",
    "        mem = []\n",
    "        for i in range(8):\n",
    "            mem.append(self.neurons[i].init_leaky())\n",
    "        \n",
    "        # record spike outputs\n",
    "        spk_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            #form inputs\n",
    "            spk_i = x[:,step]\n",
    "\n",
    "            for i in range(8):\n",
    "                if(i==6): #need to flatten from AvgPool to Linear\n",
    "                    spk_i = torch.flatten(spk_i,start_dim=1)\n",
    "                cur_i = self.layers[i](spk_i)\n",
    "                spk_i, mem[i] = self.neurons[i](cur_i,mem[i])\n",
    "\n",
    "            spk_rec.append(spk_i)\n",
    "            \n",
    "\n",
    "\n",
    "        return torch.stack(spk_rec, dim=0) #TODO do i really need to return membrane potentials\n",
    "    \n",
    "###################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''a = next(iter(test_loader))\n",
    "print(a[0].shape)\n",
    "print(a[0].dtype)\n",
    "\n",
    "net = Net().to(device)\n",
    "net.train()\n",
    "r = net.forward(a[0].to(device))\n",
    "print(\"r: \",r.shape)\n",
    "print(torch.max(r))'''\n",
    "#comment this out to reduce GPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "########### STATS ##############\n",
    "\n",
    "def print_stats(data, targets):\n",
    "    output = net(data)\n",
    "    acc  = net.accuracy_metric(output, targets)\n",
    "    #dev = np.std((targets == idx).detach().cpu().numpy()) #TODO deviation for latency encoding\n",
    "    print(f\"    Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {img_counter}, Minibatch stats:\")\n",
    "    print(f\"    Train Set Loss: {loss_hist[batch_counter]:.2f}\")\n",
    "    print(f\"    Test Set Loss: {test_loss_hist[img_counter]:.2f}\")\n",
    "    print_stats(test_data, test_targets)\n",
    "    print(\"Train batch: \")\n",
    "    print_stats(data, targets)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "############################## MAIN TRAINING LOOP ###########################################\n",
    "\n",
    "\n",
    "# Load the network onto CUDA\n",
    "net = Net().to(device)\n",
    "optimiser = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "img_counter = 0 #total no. of images iterated over\n",
    "\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    batch_counter=0 #image number within current batch\n",
    "\n",
    "    #mini-batch loop\n",
    "    for data, targets in tqdm(iter(train_loader)):\n",
    "\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        net.train() #inform pytorch\n",
    "        spk_rec = net(data)\n",
    "\n",
    "        #calculate loss as cross entropy of membrane potential at each step\n",
    "        loss_val = net.loss(spk_rec,targets)\n",
    "\n",
    "        \n",
    "        optimiser.zero_grad() #(reset for batch)\n",
    "        loss_val.backward() #calculate backpropogation error gradient\n",
    "        optimiser.step() #then update parameters\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad(): #tell pytorch to disable gradient calculation (save compute)\n",
    "            net.eval()\n",
    "\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk = net(test_data)\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = net.loss(test_spk,test_targets)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "            # Print train/test loss/accuracy\n",
    "            if img_counter % 50 == 0:\n",
    "                train_printer()\n",
    "            img_counter += 1\n",
    "            batch_counter +=1\n",
    "\n",
    "\n",
    "###############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(),\"./models/DVS2_lr_1e-4.pt\")\n",
    "'''\n",
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load(\"./models/DVS2_lr_1e-4.pt\"))\n",
    "#loss graph wont be after reload TODO\n",
    "'''\n",
    "\n",
    "# Plot Loss\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "plt.plot(loss_hist)\n",
    "plt.plot(test_loss_hist)\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "\n",
    "with torch.no_grad():\n",
    "  net.eval()\n",
    "  accs = []\n",
    "  for i, (data, targets) in enumerate(test_loader):\n",
    "    if i>100: break\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    output = net.forward(data)\n",
    "    accs.append(net.accuracy_metric(output,targets))\n",
    "  \n",
    "  print(\"mean accuracy: \",np.mean(accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
